AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31

Parameters:
  DatabasePassword:
    Type: String
    NoEcho: True
  DatabaseUsername:
    Type: String
    NoEcho: True
  DatabaseName:
    Type: String
    Default: mjcs
  StaticStackName:
    Description: Name of the static stack, for getting database and S3 bucket details
    Type: String
  DockerRepoStackName:
    Description: Name of the docker repo stack, for getting repository name
    Type: String
  EnvironmentType:
    Description: The environment type (prod or dev)
    Type: String
    Default: dev
    AllowedValues:
      - prod
      - dev
    ConstraintDescription: must be a prod or dev
  AWSRegion:
    Description: AWS Region
    Type: String
    Default: us-east-1

Resources:
  ScraperService:
    Type: AWS::ECS::Service
    Properties:
      ServiceName: !Sub mjcs_scraper_service_${EnvironmentType}
      Cluster:
        Fn::ImportValue: !Sub ${StaticStackName}-ECSClusterArn
      DesiredCount: 1
      LaunchType: FARGATE
      NetworkConfiguration:
        AwsvpcConfiguration:
          AssignPublicIp: DISABLED
          SecurityGroups:
            - Fn::ImportValue: !Sub ${StaticStackName}-VPCDefaultSecurityGroupId
          Subnets:
            - Fn::ImportValue: !Sub ${StaticStackName}-VPCPrivateSubnet1Id
            - Fn::ImportValue: !Sub ${StaticStackName}-VPCPrivateSubnet2Id
      TaskDefinition: !Ref ScraperTask
  
  ScraperTask:
    Type: AWS::ECS::TaskDefinition
    Properties:
      ContainerDefinitions:
        - Name: !Sub mjcs_scraper_container_${EnvironmentType}
          Command: [ "python", "-u", "scraper_service.py" ]
          Environment:
            - Name: DOCKER_TASK
              Value: true
            - Name: MJCS_DATABASE_URL
              Value: !Sub
                - postgresql://${db_user}:${db_pw}@${db_addr}/${db_name}
                - db_user: !Ref DatabaseUsername
                  db_pw: !Ref DatabasePassword
                  db_addr:
                    Fn::ImportValue: !Sub ${StaticStackName}-DatabaseHostname
                  db_name: !Ref DatabaseName
            - Name: SCRAPER_QUEUE_NAME
              Value: !GetAtt ScraperQueue.QueueName
            - Name: SCRAPER_FAILED_QUEUE_NAME
              Value: !GetAtt ScraperFailedQueue.QueueName
            - Name: CASE_DETAILS_BUCKET
              Value:
                Fn::ImportValue: !Sub ${StaticStackName}-CaseDetailsBucketName
          Image: !Sub
            - ${AWS::AccountId}.dkr.ecr.${AWSRegion}.amazonaws.com/${repo_name}
            - repo_name:
                Fn::ImportValue: !Sub ${DockerRepoStackName}-DockerRepoName
          LogConfiguration:
            LogDriver: awslogs
            Options:
              awslogs-create-group: true
              awslogs-region: !Ref AWSRegion
              awslogs-group: !Sub caseharvester-scraper-${EnvironmentType}
              awslogs-stream-prefix: caseharvester-scraper-logs
      RequiresCompatibilities:
        - FARGATE
      Cpu: 1024
      Memory: 2048
      ExecutionRoleArn:
        Fn::ImportValue: !Sub ${StaticStackName}-ExecutionRoleArn
      NetworkMode: awsvpc
      TaskRoleArn: !GetAtt ScraperTaskRole.Arn

  ScraperTaskRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub mjcs_ecs_scraper_task_role_${EnvironmentType}
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ecs-tasks.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSQSFullAccess
        - arn:aws:iam::aws:policy/AmazonS3FullAccess

  ScraperLambda:
    Type: AWS::Serverless::Function
    Properties:
      Handler: scraper_lambda.lambda_handler
      Runtime: python3.6
      Policies:
        - AmazonSQSFullAccess
        - VPCAccessPolicy: {}
      CodeUri: ../pkg/scraper
      MemorySize: 320
      Timeout: 900
      ReservedConcurrentExecutions: 10
      Environment:
        Variables:
          MJCS_DATABASE_URL: !Sub
            - postgresql://${db_user}:${db_pw}@${db_addr}/${db_name}
            - db_user: !Ref DatabaseUsername
              db_pw: !Ref DatabasePassword
              db_addr:
                Fn::ImportValue: !Sub ${StaticStackName}-DatabaseHostname
              db_name: !Ref DatabaseName
          SCRAPER_QUEUE_NAME: !GetAtt ScraperQueue.QueueName
      VpcConfig:
        SecurityGroupIds:
          - Fn::ImportValue: !Sub ${StaticStackName}-VPCDefaultSecurityGroupId
        SubnetIds:
          - Fn::ImportValue: !Sub ${StaticStackName}-VPCPrivateSubnet1Id
          - Fn::ImportValue: !Sub ${StaticStackName}-VPCPrivateSubnet2Id

  ScraperFailedQueue:
    Type: AWS::SQS::Queue
    Properties:
      MessageRetentionPeriod: 1209600
      VisibilityTimeout: 300
      QueueName: !Sub mjcs_scraper_failed_queue_${EnvironmentType}

  ScraperQueue:
    Type: AWS::SQS::Queue
    Properties:
      MessageRetentionPeriod: 1209600
      VisibilityTimeout: 300
      QueueName: !Sub mjcs_scraper_queue_${EnvironmentType}

  DailyScraperRule:
    Type: AWS::Events::Rule
    Properties:
      Name: !Sub daily_scraper_${EnvironmentType}
      Description: Every day, re-scrape last 30 days cases
      ScheduleExpression: cron(0 22 * * ? *)  # 6pm ET
      Targets:
        - Id: scraper_lambda_target
          Arn: !GetAtt ScraperLambda.Arn
          Input: '{ "command": "rescrape", "options": { "days_ago_start": 0, "days_ago_end": 30 } }'
  
  WeeklyScraperRule:
    Type: AWS::Events::Rule
    Properties:
      Name: !Sub weekly_scraper_${EnvironmentType}
      Description: Every week, re-scrape last 6 months cases
      ScheduleExpression: cron(0 8 ? * SUN *)  # Sunday 4am ET
      Targets:
        - Id: scraper_lambda_target
          Arn: !GetAtt ScraperLambda.Arn
          Input: '{ "command": "rescrape", "options": { "days_ago_start": 31, "days_ago_end": 182 } }'
  
  MonthlyScraperRule:
    Type: AWS::Events::Rule
    Properties:
      Name: !Sub monthly_scraper_${EnvironmentType}
      Description: Every month, re-scrape last 2 years cases
      ScheduleExpression: cron(0 8 1 * ? *)  # 1st of month 4am ET
      Targets:
        - Id: scraper_lambda_target
          Arn: !GetAtt ScraperLambda.Arn
          Input: '{ "command": "rescrape", "options": { "days_ago_start": 183, "days_ago_end": 720 } }'

  QuarterlyScraperRule:
    Type: AWS::Events::Rule
    Properties:
      Name: !Sub quarterly_scraper_${EnvironmentType}
      Description: Every 3 months, re-scrape last 6 years cases
      ScheduleExpression: cron(0 8 1 */3 ? *)  # 1st of every 3rd month 4am ET
      Targets:
        - Id: scraper_lambda_target
          Arn: !GetAtt ScraperLambda.Arn
          Input: '{ "command": "rescrape", "options": { "days_ago_start": 721, "days_ago_end": 2191 } }'

  DailyRulePermissions:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt ScraperLambda.Arn
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt DailyScraperRule.Arn
  
  WeeklyRulePermissions:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt ScraperLambda.Arn
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt WeeklyScraperRule.Arn
  
  MonthlyRulePermissions:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt ScraperLambda.Arn
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt MonthlyScraperRule.Arn
  
  QuarterlyRulePermissions:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt ScraperLambda.Arn
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt QuarterlyScraperRule.Arn

Outputs:
  ScraperFailedQueueName:
    Description: Scraper failed queue name
    Value: !GetAtt ScraperFailedQueue.QueueName
    Export:
      Name: !Sub ${AWS::StackName}-ScraperFailedQueueName
  ScraperQueueName:
    Description: Scraper queue name
    Value: !GetAtt ScraperQueue.QueueName
    Export:
      Name: !Sub ${AWS::StackName}-ScraperQueueName